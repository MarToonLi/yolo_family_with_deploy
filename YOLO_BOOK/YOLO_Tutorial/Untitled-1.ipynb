{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "============\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def singleton(cls):\n",
    "    _instance = {}\n",
    "    print(_instance)\n",
    "\n",
    "    def inner():\n",
    "        if cls not in _instance:\n",
    "            _instance[cls] = cls()\n",
    "        return _instance[cls]\n",
    "    return inner\n",
    "    \n",
    "@singleton\n",
    "class Cls(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "print(\"============\")\n",
    "cls1 = Cls()\n",
    "cls2 = Cls()\n",
    "cls3 = Cls()\n",
    "print(id(cls1) == id(cls2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 1), ('b', 2), ('c', 3), ('d', 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L=[('b',2),('a',1),('c',3),('d',4)]\n",
    "# 2、利用参数 cmp 排序\n",
    "sorted(L, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc(fun):                  # 定义装饰器函数\n",
    "    def add_info():\n",
    "        print(\"this is this.\")\n",
    "        fun()\n",
    "        \n",
    "    return add_info             #! 切记，返回函数名称\n",
    "\n",
    "@desc\n",
    "def f1():                       # 被装饰函数\n",
    "    print(\"this is f1;\")\n",
    "    \n",
    "f1()                            # 调用被装饰函数\n",
    "\n",
    "# ------------------等价形式-------------------------\n",
    "def add_info(fun):\n",
    "    print(\"this is this.\")\n",
    "    fun()\n",
    "    \n",
    "def f1():                       # 被装饰函数\n",
    "    print(\"this is f1;\")\n",
    "    \n",
    "wrap_func = add_info(f1)\n",
    "wrap_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', 'D', 's', 'E', 'k', 'O', 'Q', 'r', 'L', 'a']\n",
      "s,D,s,E,k,O,Q,r,L,a,\n",
      "运行时间：0.00000000\n",
      "s,D,s,E,k,O,Q,r,L,a\n",
      "运行时间：0.00000000\n",
      "运行时间：0.00000000\n",
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "运行时间：0.00000000\n",
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "这是fun_list函数\n",
      "fun_list\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import string\n",
    "import functools\n",
    "\n",
    "li = [random.choice(string.ascii_letters) for i in range(10)]\n",
    "print(li)\n",
    "\n",
    "def decorator(fun):\n",
    "    #\"\"\"这是一个装饰器\"\"\"\n",
    "    ##这的参数要和装饰器的参数一致,没有这一行打印的是默认的文档，\n",
    "\t# 就是wrapper函数的帮助文档\n",
    "    @functools.wraps(fun)      \n",
    "    def wrapper(*args,**kwargs):\n",
    "        #\"\"\"这是一个wrapper函数\"\"\"\n",
    "        t1 = time.time()\n",
    "        f = fun(*args,**kwargs)\n",
    "        t2 = time.time()\n",
    "        print('运行时间：%.8f' %(t2 - t1))\n",
    "        return f\n",
    "    return wrapper\n",
    "\n",
    "# 无参数无返回值函数1\n",
    "@decorator\n",
    "def con_add():\n",
    "    s = ''\n",
    "    for i in li:\n",
    "        s += (i + ',')\n",
    "    print(s)\n",
    "\n",
    "# 无参数无返回值函数2\n",
    "@decorator\n",
    "def join_add():\n",
    "    print(','.join(li))\n",
    "\n",
    "# 有参数有返回值函数1\n",
    "@decorator\n",
    "def fun_list(n):\n",
    "    \"\"\"这是fun_list函数\"\"\"\n",
    "    return [i * 2 for i in range(n)]\n",
    "\n",
    "# 有参数有返回值函数2\n",
    "@decorator\n",
    "def fun_map(n):\n",
    "    return list(map(lambda x:x*2,range(n)))\n",
    "\n",
    "con_add()\n",
    "join_add()\n",
    "print(fun_list(10))\n",
    "print(fun_map(10))\n",
    "print(fun_list.__doc__)\n",
    "print(fun_list.__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get in decorator_b\n",
      "Get in decorator_a\n",
      "Get in inner_a\n",
      "Get in inner_b\n",
      "Get in f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decorator_a(fun):\n",
    "    print('Get in decorator_a')\n",
    "    def inner_a(*args, **kwargs):\n",
    "        print('Get in inner_a')\n",
    "        res = fun(*args, **kwargs)\n",
    "        return res\n",
    "    return inner_a\n",
    "\n",
    "def decorator_b(fun):\n",
    "    print('Get in decorator_b')\n",
    "    def inner_b(*args, **kwargs):\n",
    "        print('Get in inner_b')\n",
    "        res = fun(*args, **kwargs)\n",
    "        return res\n",
    "    return inner_b\n",
    "\n",
    "@decorator_a\n",
    "@decorator_b\n",
    "def f(x):\n",
    "    print('Get in f')\n",
    "    return x * 2\n",
    "f(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models - YOLOV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`init_prob = 0.01`\n",
    "\n",
    "`bias_value = -torch.log(torch.tensor((1. - init_prob) / init_prob))`\n",
    "\n",
    "这里的 init_prob = 0.01 表示初始时，网络预测正类的概率设为0.01，即模型一开始假设几乎所有的输出都是负类（非目标类）。这种设置在目标检测中很常见，因为在大多数情况下，任意一个区域包含目标的概率通常很低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss\n"
     ]
    }
   ],
   "source": [
    "# 这里的 init_prob = 0.01 表示初始时，网络预测正类的概率设为0.01，即模型一开始假设几乎所有的输出都是负类（非目标类）。这种设置在目标检测中很常见，因为在大多数情况下，任意一个区域包含目标的概率通常很低。\n",
    "print(\"ss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5951)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.5951)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_prob = 0.01\n",
    "bias_value = -torch.log(torch.tensor((1. - init_prob) / init_prob)) \n",
    "bias_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.595119953155518"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_value.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor.item方法：only one element tensors can be converted to Python scalars\n",
    "# torch.tensor([0,1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造一个类scores的数组\n",
    "\n",
    "# 设置随机种子以便重现结果\n",
    "np.random.seed(0)\n",
    "\n",
    "# 定义参数\n",
    "num_boxes = 10  # 假设有 10 个预测框\n",
    "num_classes = 6  # 假设有 80 个类（如 COCO 数据集）\n",
    "\n",
    "# 生成一个随机的 scores 矩阵\n",
    "# 每个分数在 0 到 1 之间\n",
    "scores = np.random.rand(num_boxes, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 6)\n",
      "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411]\n",
      " [0.43758721 0.891773   0.96366276 0.38344152 0.79172504 0.52889492]\n",
      " [0.56804456 0.92559664 0.07103606 0.0871293  0.0202184  0.83261985]\n",
      " [0.77815675 0.87001215 0.97861834 0.79915856 0.46147936 0.78052918]\n",
      " [0.11827443 0.63992102 0.14335329 0.94466892 0.52184832 0.41466194]\n",
      " [0.26455561 0.77423369 0.45615033 0.56843395 0.0187898  0.6176355 ]\n",
      " [0.61209572 0.616934   0.94374808 0.6818203  0.3595079  0.43703195]\n",
      " [0.6976312  0.06022547 0.66676672 0.67063787 0.21038256 0.1289263 ]\n",
      " [0.31542835 0.36371077 0.57019677 0.43860151 0.98837384 0.10204481]\n",
      " [0.20887676 0.16130952 0.65310833 0.2532916  0.46631077 0.24442559]]\n",
      "(10,)\n",
      "[1 2 1 2 3 1 2 0 4 2]\n"
     ]
    }
   ],
   "source": [
    "print((scores.shape))\n",
    "print(scores)\n",
    "labels = np.argmax(scores, axis=1)\n",
    "print(labels.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[0.71518937 0.96366276 0.92559664 0.97861834 0.94466892 0.77423369\n",
      " 0.94374808 0.6976312  0.98837384 0.65310833]\n",
      "(10, 10)\n",
      "[[0.71518937 0.60276338 0.71518937 0.60276338 0.54488318 0.71518937\n",
      "  0.60276338 0.5488135  0.4236548  0.60276338]\n",
      " [0.891773   0.96366276 0.891773   0.96366276 0.38344152 0.891773\n",
      "  0.96366276 0.43758721 0.79172504 0.96366276]\n",
      " [0.92559664 0.07103606 0.92559664 0.07103606 0.0871293  0.92559664\n",
      "  0.07103606 0.56804456 0.0202184  0.07103606]\n",
      " [0.87001215 0.97861834 0.87001215 0.97861834 0.79915856 0.87001215\n",
      "  0.97861834 0.77815675 0.46147936 0.97861834]\n",
      " [0.63992102 0.14335329 0.63992102 0.14335329 0.94466892 0.63992102\n",
      "  0.14335329 0.11827443 0.52184832 0.14335329]\n",
      " [0.77423369 0.45615033 0.77423369 0.45615033 0.56843395 0.77423369\n",
      "  0.45615033 0.26455561 0.0187898  0.45615033]\n",
      " [0.616934   0.94374808 0.616934   0.94374808 0.6818203  0.616934\n",
      "  0.94374808 0.61209572 0.3595079  0.94374808]\n",
      " [0.06022547 0.66676672 0.06022547 0.66676672 0.67063787 0.06022547\n",
      "  0.66676672 0.6976312  0.21038256 0.66676672]\n",
      " [0.36371077 0.57019677 0.36371077 0.57019677 0.43860151 0.36371077\n",
      "  0.57019677 0.31542835 0.98837384 0.57019677]\n",
      " [0.16130952 0.65310833 0.16130952 0.65310833 0.2532916  0.16130952\n",
      "  0.65310833 0.20887676 0.46631077 0.65310833]]\n"
     ]
    }
   ],
   "source": [
    "scores2 = scores[(np.arange(scores.shape[0]), labels)]\n",
    "scores3 = scores[:, labels]\n",
    "\n",
    "print(scores2.shape)\n",
    "print(scores2)\n",
    "\n",
    "print(scores3.shape)\n",
    "print(scores3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function B is called\n",
      "Function A is called\n"
     ]
    }
   ],
   "source": [
    "# Python 允许函数定义前对该函数的调用！\n",
    "def A():\n",
    "    B()  # 尝试调用 B 函数\n",
    "    print(\"Function A is called\")\n",
    "\n",
    "def B():\n",
    "    print(\"Function B is called\")\n",
    "\n",
    "A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 3 1 4 6 2 5 0 7 9]\n",
      "[8 3 1 4 6 2 5 0 7 9]\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nnumpy中array默认的数据格式是int64类型，而torch中tensor默认的数据格式是float32类型。\\nas_tensor和from_numpy是浅拷贝，而tensor和Tensor则是属于深拷贝，浅拷贝是直接共享内存内存空间的，这样效率更高，而深拷贝是直接创建一个新的副本。\\n原文链接：https://blog.csdn.net/qq_42346574/article/details/120100424\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NMS中根据置信度分数将预测框进行倒序排列\n",
    "\n",
    "scores2 = scores[(np.arange(scores.shape[0]), labels)]\n",
    "\n",
    "\n",
    "order1 = scores2.argsort()[::-1] \n",
    "torch_scores2 = torch.tensor(scores2)\n",
    "order2 = torch_scores2.argsort(descending=True).numpy()\n",
    "\n",
    "print(order1)\n",
    "print(order2)\n",
    "print(np.sum((order1 == order2)))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "numpy中array默认的数据格式是int64类型，而torch中tensor默认的数据格式是float32类型。\n",
    "as_tensor和from_numpy是浅拷贝，而tensor和Tensor则是属于深拷贝，浅拷贝是直接共享内存内存空间的，这样效率更高，而深拷贝是直接创建一个新的副本。\n",
    "原文链接：https://blog.csdn.net/qq_42346574/article/details/120100424\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4423863626941616\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.beta(32.0, 32.0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1875\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "a = 38\n",
    "b = 32\n",
    "print(a/ b)\n",
    "\n",
    "print(int(1.1))\n",
    "print(int(1.5))\n",
    "print(int(1.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  3, 20, 20, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1 = [22, 3, 20, 20, 10]\n",
    "\n",
    "torch.tensor(shape1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3721,  0.6994,  0.2631],\n",
       "        [-1.1298, -0.3909,  0.3057],\n",
       "        [-0.1814,  0.5260,  0.4014]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "output = torch.randn(3,3)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5920, 0.6681, 0.5654],\n",
      "        [0.2442, 0.4035, 0.5758],\n",
      "        [0.4548, 0.6285, 0.5990]])\n",
      "tensor(0.8056)\n"
     ]
    }
   ],
   "source": [
    "active_func = nn.Sigmoid()\n",
    "output = active_func(output)\n",
    "print(output)\n",
    "\n",
    "target = torch.FloatTensor([[0,1,1],[1,1,1],[0,0,0]])\n",
    "loss = nn.BCELoss(reduction=\"mean\")\n",
    "loss = loss(output, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.4713)\n",
      "tensor(6.4713)\n",
      "tensor(0.7190)\n",
      "tensor(0.7190)\n"
     ]
    }
   ],
   "source": [
    "loss_obj = F.binary_cross_entropy_with_logits(output, target, reduction='none')\n",
    "print(loss_obj.sum())\n",
    "loss_obj_sum = F.binary_cross_entropy_with_logits(output, target, reduction='sum')\n",
    "print(loss_obj_sum)\n",
    "loss_obj_mean = F.binary_cross_entropy_with_logits(output, target, reduction='mean')\n",
    "print(loss_obj_mean)\n",
    "\n",
    "loss2 = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "loss2 = loss2(output, target)\n",
    "\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3] + [4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\n",
    "    \"a\" : 1, \"b\" : 2\n",
    "}\n",
    "\n",
    "list(a.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatchNorm2d(nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1,\n",
    "                 affine=True, track_running_stats=True):\n",
    "        super(MyBatchNorm2d, self).__init__(\n",
    "            num_features, eps, momentum, affine, track_running_stats)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # ...\n",
    "        exponential_average_factor = 0.1\n",
    "        \n",
    "        # calculate running estimates\n",
    "        if self.training:\n",
    "            mean = input.mean([0, 2, 3])\n",
    "            # use biased var in train\n",
    "            var = input.var([0, 2, 3], unbiased=False)\n",
    "            n = input.numel() / input.size(1)\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = exponential_average_factor * mean\\\n",
    "                    + (1 - exponential_average_factor) * self.running_mean\n",
    "                # update running_var with unbiased var\n",
    "                self.running_var = exponential_average_factor * var * n / (n - 1)\\\n",
    "                    + (1 - exponential_average_factor) * self.running_var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        input = (input - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))\n",
    "        if self.affine:\n",
    "            input = input * self.weight[None, :, None, None] + self.bias[None, :, None, None]\n",
    "\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([5, 10, 15])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntorch.Size([5])\\ntorch.Size([5, 10, 15])\\ntorch.Size([5])\\ntorch.Size([5])\\ntorch.Size([5])\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image Example\n",
    "N, C, H, W = 20, 5, 10, 15\n",
    "input0 = torch.randn(N, C, H, W)\n",
    "\n",
    "batch_norm = nn.BatchNorm2d(C)\n",
    "layer_norm = nn.LayerNorm([C, H, W]) # 参数量为C*H*W*2\n",
    "insta_norm1 = nn.InstanceNorm2d(5, affine=True)\n",
    "group_norm1 = nn.GroupNorm(1, 5)\n",
    "group_norm2 = nn.GroupNorm(5, 5)\n",
    "\n",
    "print(batch_norm.weight.shape)\n",
    "print(layer_norm.weight.shape)\n",
    "print(insta_norm1.weight.shape)\n",
    "print(group_norm1.weight.shape)\n",
    "print(group_norm2.weight.shape)\n",
    "\n",
    "\"\"\"\n",
    "torch.Size([5])\n",
    "torch.Size([5, 10, 15])\n",
    "torch.Size([5])\n",
    "torch.Size([5])\n",
    "torch.Size([5])\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random.normal(shape=[20, 1, 5, 10, 15])\n",
    "mean, var = tf.nn.moments(x, axes =[2, 3, 4], keepdims=True)\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 3 \n",
    "input_size = 2\n",
    "# 假设输入特征为 x\n",
    "x = torch.randn(batch_size, input_size)\n",
    "# 权重和偏置\n",
    "w = torch.randn(input_size, 1)\n",
    "b = torch.randn(1)\n",
    "\n",
    "# 逻辑回归输出\n",
    "logits = torch.matmul(x, w) + b\n",
    "predictions = torch.sigmoid(logits)\n",
    "\n",
    "print(predictions.shape)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 假设 y 是标签\n",
    "y = torch.tensor([0.0, 1.0, 1.0])  # 转为浮点数\n",
    "y = y.view(-1, 1)  # 修改形状为 (3, 1)\n",
    "loss = criterion(predictions, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1,4,2,3,4,1]\n",
    "l2 = list(set(l1))\n",
    "l2.sort(key=l1.index)\n",
    "print(l2)\n",
    "\n",
    "l1.index(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2479410090624\n",
      "2479410090624\n",
      "2479410282368\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "a = [\"张小鸡\"]\n",
    "b = a\n",
    "c = copy.copy(a)\n",
    "\n",
    "print(id(a))\n",
    "print(id(b))\n",
    "print(id(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\MarkDownFiles\\ProjectsOfCamapny\n",
      "['公司项目总结.assets']\n",
      "['公司项目总结.md']\n",
      "F:\\MarkDownFiles\\ProjectsOfCamapny\\公司项目总结.assets\n",
      "[]\n",
      "['image-20240902205420174.png', 'image-20240912132332470.png', 'image-20240925184007709.png', 'image-20240926110803304.png', 'image-20240926145848046.png', 'image-20240926145929707.png', 'image-20241008145039033.png', 'image-20241008154423190.png', 'image-20241008154432518.png', 'image-20241012163017123.png', 'image-20241023101628131.png', 'image-20241024150256436.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root, dirs, filenmae in os.walk(\"F:\\MarkDownFiles\\ProjectsOfCamapny\"):\n",
    "    print(root)\n",
    "    print(dirs)\n",
    "    print(filenmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "a = 257\n",
    "b = 257\n",
    "print(a is b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "c = 256\n",
    "d = 256\n",
    "print(c is d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "e = 256\n",
    "f = e\n",
    "print(e is f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10\n"
     ]
    }
   ],
   "source": [
    "x=9\n",
    "print(~x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
