# Yolo Family 学习笔记

>
>
>1. 无法理解就记住它；
>2. 有些网络层的结构是需要死记硬背下来的；

## YoloV1算法原理

>[【YOLO系列】YOLOv1论文超详细解读（翻译 ＋学习笔记）_yolo论文-CSDN博客](https://blog.csdn.net/weixin_43334693/article/details/129011644)

### 背景

1. RCNN系列算法基于滑动窗口或者区域提议方法。缺点是速度比较慢；
2. YOLO的创新：将物体检测框架构建成回归问题，直接从图像像素预测到边界框坐标和类别的概率；它平衡了准确率和速度，虽然准确度在v1时并不高；它实现了端到端的训练，不再需要预处理，通过分割的方式计算得到mask；

### 实现方式

1. 端到端过程：将输入图像resize得到448的大小；执行卷积；非极大值抑制，得到结果；
2. 非极大值抑制的过程：

> - 从所有候选框列表L中选择置信度最高的预测边界框B1作为基准，然后遍历剩下的候选框，将所有候选框中与B1的IOU值超过设定阈值的候选框从候选框列表L中剔除；
> - 从更新后的候选框列表L中选择置信度第二高的预测边界框B2作为基准，然后遍历剩下的候选框，将所有候选框中与B2的IOU值超过设定阈值的候选框从候选框列表中剔除；
> - 重复上述操作，**直到候选框列表L中所有的预测狂都被当作基准。**

3. 该回归问题：它将图像分割成一张S * S的网格，而每个网格单元预测B组边界框、置信度和C个类别的概率。这些预测项被编码成一个S * S * (B * 5 + C)的张量。**其中，B*5+C的信息保存到了通道（通道有了物理意义）上**。其中一个框的位置以及是否为前景或背景。
4. YOLOV1中，固定网络层的输入是448 * 448 * 3，经过网络达到最后一个卷积层 7 * 7 * 1024，最后 该张量拉成一维张量 50176，经过全连接层变成4096一维张量，此时再reshape成7 * 7 * 30 （5 + 5 + 20）的具有实际意义的张量。

> 三维张量转化为一维张量，其实对于准确率有损失；但是基于全连接层强大的非线性表达能力，因此网络仍然具备一定的准确率；

5. 下采样的方式：步长不等于1的卷积和步长不等于1的池化层；目前通常使用步长为2的卷积来代替池化层。
6. loss损失函数。损失函数包含三方面的内容：坐标损失、目标存在置信度损失和分类概率损失。

> 1. 坐标损失：X坐标的误差平方、Y坐标的误差平方和、W根号的误差平方和和H根号的误差平方和。
> 2. 









## 大知识整理

1. 模型推理时为什么与置信度阈值比较的不是类别的置信度分数，而是类别置信度分数与目标是否存在的置信度分数的乘积？

   > 1. 本质上，**类别的置信度分数本身是不考虑目标存在的置信度分数**，如果只考虑类别的置信度分数，容易产生误报；
   > 2. 乘积的方式，**综合考虑**了目标存在概率以及目标所属类别概率两方面的内容。只有当目标存在置信度和目标类别置信度都很高的时候，才会认为检测有效。

2. 位置损失计算时，为什么对W和H在根号的情况下进行误差平方和的计算？

   > 1. 本质上，是为了缓解大小目标尺寸**对损失函数影响程度不同**的问题。
   >
   > 2. **需要注意，坐标计算中的WYWH都是归一化值，下图在思考的时候不应关注在Δ，而是大H根号和小H根号的差值****有没有**小于大H和小H之间的差值**。
   >
   >    ![img](readme.assets/b49b354a29d38c910c0c393da82c9199.png)

3. 